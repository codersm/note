---
title: 缓存
date: 2017-08-21 13:05:05
tags: 缓存
---
# 缓存

任何平台随着用户规模的扩大、功能不断的添加，持久化数据库层承受的读写压力会越来越大，一旦数据库承压过大会导致读写性能陡然下降，严重时会导致大量的业务请求超时，进而发生“雪崩”引发严重的故障。

在业务层和数据库持久层之间引入一层内存缓存层，对于复杂且业务逻辑上不会变化的查询结果进行缓存，业务请求再次发起时，每次都先从缓存层中查询，从而大大减少对数据库的查询，减小对数据库的压力。

## 缓存类型

缓存就是将数据存放在距离计算最近的位置以加快处理速度，是改变软件性能的第一手段。

- CDN

    即内容分发网络，部署在距离终端用户最近的网络服务商，用户的网络请求总是先到达他的网络服务商那里，在这里缓存网站的一些静态资源，可以就近以最快的数据返回给用户，如视频网站和门户网站会将用户访问量大的热点内容缓存在CDN。

- 浏览器缓存

    对于网站应用而言，css，javascript，logo。。。这些静态资源文件更新的频率都比较低，这些文件又几乎每次HTTP请求都需要，如果将这些文件缓存在浏览器中，可以很好的改善网站的性能。通过设置HTTP头中Cache-Control和Expire的属性，可设定浏览器缓存，缓存的时间可以是数天，甚至是几个月。

- 反向代理

    反向代理属于网站前端架构的一部分，部署在网站的前端，当用户请求到达网站的数据中心时，最先访问到的就是反向代理服务器，这里缓存网站的静态资源，无需将请求继续转发给应用服务器就能返回给用户。

- 本地缓存

    在应用服务器本地缓存着热点数据，应用程序可以在本机内存直接访问数据，无需访问数据库。

    ![本地缓存](http://i1.bvimg.com/598959/afcea62fe8a2249b.png)

- 集中式缓存

    大型网站的数据量非常庞大，即使只缓存一小部分，需要的内容空间也不是单机能承受的，所以除了本地缓存，还需要分布式缓存，将数据缓存在一个专门的分布式缓存集群中，应用程序通过网络通信访问缓存数据。

    ![集中式缓存](http://i1.bvimg.com/598959/4337a12d52695e78.png)

- 分布式缓存

    ![分布式缓存](http://i1.bvimg.com/598959/a1e491e71fc6bee2.png)

- 数据库的缓存

    目前主流的数据库都提供了查询缓存，不同的数据库有着不同的实现，比如Oracle会在SGA开辟专门的查询缓存，当Oracle接收到一条查询语句之后，首先会进行语法，语义检查，然后会查看缓存是否有相同的语句，如果有则选择已经生成的执行计划和优化方案，如果没有命中，则Oracle会进行相应的解析生成相应的执行计划和优化方案，然后对查询数据进行hash算法存储到缓存中。

    使用缓存有两个前提条件：

    ①数据访问热点不均衡，某些数据会被更频繁的访问，这些数据应该放在缓存中；

    ②数据在某个时间段内有效，不会很快过期，否则缓存的数据就会因已经失效而产生脏读，影响结果的正确性。


**分布式内存缓存、本地单点缓存、应用层缓存对比**

| 类型      | 稳定性                                             | 扩展性            | 通用性                         | 对代码的侵入性                   |
| ------- | ----------------------------------------------- | -------------- | --------------------------- | ------------------------- |
| 应用层缓存   | 应用会频繁重启更新，缓存易丢失，稳定性不佳                           | 差，受限于进程的资源限制   | 差，不同应用难以复用                  | 代码侵入性小，无网络操作，只需要操作应用进程内存  |
| 本地单点缓存  | 独立的缓存应用（redis、memcached等），不会频繁重启，稳定性一般，但有单点故障问题 | 一般，受限于单服务器资源限制 | 一般，业务应用和缓存应用有强耦合            | 代码侵入性一般，需要引入对应的api通常有网络操作 |
| 分布式内存缓存 | 分布式系统，具备故障自动恢复功能，无单点故障问题，稳定性佳                   | 好，支持水平扩展       | 好，对业务层提供通用接口，后端具体的缓存应用对业务透明 | 代码侵入性一般，需要引入通用的api通常有网络操作 |

## 缓存的设计与策略

### 缓存对象

### 更新策略

Cache Design Pattern

- 被动失效

    缓存中的数据主要用来满足读的请求。被动失效策略是指对缓存中的数据设置一个失效的时间，或当数据库中的数据有更新的时候，删除掉缓存中的数据。当再次请求的时候，发现数据已经不再或者已经失效了，则需要重新访问数据库，然后更新缓存。

    被动失效策略中存在一个问题：从缓存失效或者丢失开始直到新的数据再次被更新到缓存中的这段时间，所有的读请求都将会直接落到数据库上；而对于一个大访问量的系统来说，这有可能会带来风险。这就需要另外一种更新策略。

   > 常见的被动失效策略有：LRU/LIRS/FIFO算法剔除、超时剔除。

- 主动更新

    主动更新主要是为了解决空窗期的问题，但是这同样会带来另一个问题，就是并发更新的情况；

    在集群环境下，多台应用服务器同时访问一份数据是很正常的，这样就会存在一台服务器读取并修改了缓存数据，但是还没来得及写入的情况下，另一台服务器也读取并修改旧的数据，这时候，后写入的将会覆盖前面的，从而导致数据丢失；这也是分布式系统开发中，必然会遇到的一个问题。

    解决的方式主要有三种：

    - 锁控制
    
        这种方式一般在客户端实现（在服务端加锁是另外一种情况），其基本原理就是使用读写锁，即任何进程要调用写方法时，先要获取一个排他锁，阻塞住所有的其他访问，等自己完全修改完后才能释放；如果遇到其他进程也正在修改或读取数据，那么则需要等待； 锁控制虽然是一种方案，但是很少有真的这样去做的，其缺点显而易见，其并发性只存在于读操作之间，只要有写操作存在，就只能串行。
    
    - 版本控制
       
        这种方式也有两种实现，一种是单版本机制，即为每份数据保存一个版本号，当缓存数据写入时，需要传入这个版本号，然后服务端将传入的版本号和数据当前的版本号进行比对，如果大于当前版本，则成功写入，否则返回失败；这样解决方式比较简单；但是增加了高并发下客户端的写失败概率。 

    - 多版本控制

        即存储系统为每个数据保存多份，每份都有自己的版本号，互不冲突，然后通过一定的策略来定期合并，再或者就是交由客户端自己去选择读取哪个版本的数据。很多分布式缓存一般会使用单版本机制，而很多NoSQL则使用后者。

## 选型指标

现在可供我们选择使用的（伪）分布式缓存系统不要太多，比如使用广泛的Memcached、最近炒得火热的Redis等；这里前面加个伪字，意思是想说，有些所谓的分布式缓存其实仍是以单机的思维去做的，不能算是真正的分布式缓存（你觉得只实现个主从复制能算分布式么？）。

既然有这么多的系统可用，那么我们在选择的时候，就要有一定的标准和方法。只有有了标准，才能衡量一个系统时好时坏，或者适不适合，选择就基本有了方向。

### 容量

废话，容量当然是越大越好了，这还用说么，有100G我干嘛还要用10G？其实这么说总要考虑一下成本啦，目前一台普通的PC Server内存128G已经算是大的了，再大的话不管是从硬件还是从软件方面，管理的成本都会增加。单机来讲，比如说主板的插槽数量，服务器散热、操作系统的内存分配、回收、碎片管理等等都会限制内存卡的容量；即便使用多机的话，大量内存的采购也是很费money的！

每个系统在初期规划的时候，都会大致计算一下所要消耗的缓存空间，这主要取决于你要缓存的对象数量和单个对象的大小。一般来说，你可以采用对象属性在内存中的存储长度简单加和的方法来计算单个对象的体积，再乘以缓存对象的数量和预期增长（当然，这里边有一个热点数据的问题，这里就不细讨论了），大概得出需要使用的缓存空间；之后就可以按照这个指标去申请缓存空间或搭建缓存系统了。

### 并发量

 这里说并发量，其实还不如说是QPS更贴切一些，因为我们的缓存不是直接面向用户的，而只面向应用的，所以肯定不会有那个高的并发访问（当然，多个系统共用一套缓存那就另当别论了）；所以我们关心的是一个缓存系统平均每秒能够承受多少的访问量。

我们之所以需要缓存系统，就是要它在关键时刻能抗住我们的数据访问量的；所以，缓存系统能够支撑的并发量是一个非常重要的指标，如果它的性能还不如关系型数据库，那我们就没有使用的必要了。

### 响应时间

响应时间当然也是必要的，如果一个缓存系统慢的跟蜗牛一样，甚至直接就超时了，那和我们使用MySQL也没啥区别了。

一般来说，要求一个缓存系统在1ms或2ms之内返回数据是不过分的，当然前提是你的数据不会太大；如果想更快的话，那你就有点过分了，除非你是用的本地缓存；因为一般而言，在大型IDC内部，一个TCP回环（不携带业务数据）差不多就要消耗掉0.2ms至0.5ms。

大部分的缓存系统，由于是基于内存，所以响应时间都很短，但是问题一般会出现在数据量和QPS变大之后，由于内存管理策略、数据查找方式、I/O模型、业务场景等方面的差异，响应时间可能会差异很多，所以对于QPS和响应时间这两项指标，还要靠上线前充分的性能测试来进一步确认，不能只单纯的依赖官方的测试结果。

### 使用成本

一般分布式缓存系统会包括服务端和客户端两部分，所以其使用成本上也要分为两个部分来讲；

首先服务端，优秀的系统要是能够方便部署和方便运维的，不需要高端硬件、不需要复杂的环境配置、不能有过多的依赖条件，同时还要稳定、易维护；

而对于客户端的使用成本来说，更关系到程序员的开发效率和代码维护成本，基本有三点：单一的依赖、简洁的配置和人性化的API。

另外有一点要提的是，不管是服务端还是客户端，丰富的文档和技术支持也是必不可少的。

###  扩展性

缓存系统的扩展性是指在空间不足的性情况，能够通过增加机器等方式快速的在线扩容。这也是能够支撑业务系统快速发展的一个重要因素。

一般来讲，分布式缓存的负载均衡策略有两种，一种是在客户端来做，另外一种就是在服务端来做。

- 客户端负载均衡

    在客户端来做负载均衡的，诸如前面我们提到的Memcached、Redis等，一般都是通过特定Hash算法将key对应的value映射到固定的缓存服务器上去，这样的做法最大的好处就是简单，不管是自己实现一个映射功能还是使用第三方的扩展，都很容易；但由此而来的一个问题是我们无法做到failover。比如说某一台Memcached服务器挂掉了，但是客户端还会傻不啦叽的继续请求该服务器，从而导致大量的线程超时；当然，因此而造成的数据丢失是另外一回事了。要想解决，简单的可能只改改改代码或者配置文件就ok了，但是像Java这种就蛋疼了，有可能还需要重启所有应用以便让变更能够生效。

    如果线上缓存容量不够了，要增加一些服务器，也有同样的问题；而且由于hash算法的改变，还要迁移对应的数据到正确的服务器上去。

- 服务端负载均衡

    如果在服务端来做负载均衡，那么我们前面提到的failover的问题就很好解决了；客户端能够访问的所有的缓存服务器的ip和端口都会事先从一个中心配置服务器上获取，同时客户端会和中心配置服务器保持一种有效的通信机制（长连接或者HeartBeat），能够使后端缓存服务器的ip和端口变更即时的通知到客户端，这样，一旦后端服务器发生故障时可以很快的通知到客户端改变hash策略，到新的服务器上去存取数据。
            
    但这样做会带来另外一个问题，就是中心配置服务器会成为一个单点。解决办法就将中心配置服务器由一台变为多台，采用双机stand by方式或者zookeeper等方式，这样可用性也会大大提高。

### 容灾

我们使用缓存系统的初衷就是当数据请求量很大，数据库无法承受的情况，能够通过缓存来抵挡住大部分的请求流量，所以一旦缓存服务器发生故障，而缓存系统又没有一个很好的容灾措施的话，所有或部分的请求将会直接压倒数据库上，这可能会直接导致DB崩溃。

并不是所有的缓存系统都具有容灾特性的，所以我们在选择的时候，一定要根据自己的业务需求，对缓存数据的依赖程度来决定是否需要缓存系统的容灾特性。

## 数据对象序列化

由于独立于应用系统，分布式缓存的本质就是将所有的业务数据对象序列化为字节数组，然后保存到自己的内存中。所使用的序列化方案也自然会成为影响系统性能的关键点之一。

一般来说，我们对一个序列化框架的关注主要有以下几点：

a **序列化速度**；即对一个普通对象，将其从内存对象转换为字节数组需要多长时间；这个当然是越快越好；

b **对象压缩比**；即序列化后生成对象的与原内存对象的体积比；

c **支持的数据类型范围**；序列化框架都支持什么样的数据结构；对于大部分的序列化框架来说，都会支持普通的对象类型，但是对于复杂对象（比如说多继承关系、交叉引用、集合类等）可能不支持或支持的不够好；

d **易用性**；一个好的序列化框架必须也是使用方便的，不需要用户做太多的依赖或者额外配置；

对于一个序列化框架来说，以上几个特性很难都做到很出色，这是一个鱼和熊掌不可兼得的东西（具体原因后面会介绍），但是终归有自己的优势和特长，需要使用者根据实际场景仔细考量。


## 缓存穿透

缓存穿透是指查询一个一定不存在的数据，由于缓存不命中，并且出于容错考虑， 如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。

缓存穿透对底层数据源(mysql, hbase, http接口, rpc调用等等)压力过大，有些底层数据源不具备高并发性。

**解决方案**

- 缓存空对象

    ![缓存空对象流程图](http://i4.bvimg.com/598959/df37a250bec2fad1.png)

    缓存空对象，意味着缓存系统中存了更多的key-value，也就是需要更多空间。可以通过设置一个较短的过期时间。

    数据会有一段时间窗口的不一致，假如，Cache设置了5分钟过期，此时Storage确实有了这个数据的值，那此段时间
    就会出现数据不一致。解决方法是我们可以利用消息或者其他方式，清除掉Cache中的数据。


- bloomfilter或者压缩filter提前拦截

  ![使用bloomfilter提前拦截](http://i2.bvimg.com/598959/4c19eca026e7ed8a.png)

    在访问所有资源(cache, storage)之前，将存在的key用布隆过滤器提前保存起来，做第一层拦截, 例如： 我们的推荐服务有4亿个用户uid, 我们会根据用户的历史行为进行推荐（非实时），所有的用户推荐数据放到hbase中，但是每天有许多新用户来到网站，这些用户在当天的访问就会穿透到hbase。为此我们每天4点对所有uid做一份布隆过滤器。如果布隆过滤器认为uid不存在，那么就不会访问hbase，在一定程度保护了hbase（减少30%左右）。

## 缓存雪崩

![缓存雪崩](http://i2.bvimg.com/598959/3bf3e016d4dc9076.png)

如果Cache层由于某些原因(宕机、cache服务挂了或者不响应了)整体crash掉了，也就意味着所有的请求都会达到Storage层，所有Storage的调用量会暴增，所以它有点扛不住了，甚至也会挂掉。

**如何预防缓存雪崩**

 保证Cache服务高可用性

 依赖隔离组件为后端限流(hystrix)

## 无底洞问题

键值数据库或者缓存系统，由于通常采用hash函数将key映射到对应的实例，造成key的分布与业务无关，但是由于数据量、访问量的需求，需要使用分布式后（无论是客户端一致性哈性、redis-cluster、codis），批量操作比如批量获取多个key(例如redis的mget操作)，通常需要从不同实例获取key值，相比于单机批量操作只涉及到一次网络操作，分布式批量操作会涉及到多次网络io。

用一句通俗的话总结：更多的机器不代表更多的性能，所谓“无底洞”就是说投入越多不一定产出越多。

分布式又是不可以避免的，因为我们的网站访问量和数据量越来越大，一个实例根本坑不住，所以如何高效的在分布式缓存和存储批量获取数据是一个难点。


## 热点key问题


## 参考资料

[浅谈Web系统设计之缓存](http://www.jianshu.com/p/345f26baa589)

[大型web系统数据缓存设计](http://data.qq.com/article?id=2879)

[缓存研究](http://gaofulai1988.iteye.com/blog/2255997)

采用一致性hash算法


